# ML-Classification-problem-penDigits-Dataset
project Machine Learning Classification problem using penDigits-Dataset with SVM , Bagging Classifier,Boosting Classifier,Decision Tree classification,Hard and soft Voting Classifiers Models
# Conclusion:
During this Project I learned how to apply different classification techniques, such as 
decision tree classifier, and apply bagging and boosting with the best estimator and learning 
rate.
After comparing the models with each other, I noticed that the decision tree model is the 
lowest accuracy, which is 0.92, and the SVM model is the highest accuracy, which is 0.98
After applying soft voting and hard voting, the hard voting is the best, which have accuracy =
0.94, and the soft voting is the worst, which have accuracy = 0.92.
After comparing bagging and boosting, the best accuracy is boosting classifier, which have 
accuracy = 0.965,
When comparing the XGBOOST model(with the best number of estimator and 
hyperparameter like the boosting classifier) with Gradient Boosting classifier, the accuracy of 
XGBOOST is the higher which ism = 0.9668
